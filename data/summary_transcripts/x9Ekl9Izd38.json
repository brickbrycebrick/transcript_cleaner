{
  "video_id": "x9Ekl9Izd38",
  "youtube_transcript": "time, we're going to be talking about AI, global AI, of course we've been talking about that all week. But first time on the show scale. AI founder and CEO Alexander Wang, his company provides accurately labeled data to help companies train their AI tools. And back in 2022, he became the youngest self-made billionaire in the world. Pretty amazing. >> Thanks for having. >> Me on. I want to go straight to what we were just talking about off camera, which is the idea of where the US is on AI versus China, because you have some very surprising statistics that I think will probably, frankly, freak out some of the viewers. So yeah, first of all, the. >> The AI. >> Race and the AI war between. >> Us and China, I think is one of the most important issues of today. We took out a full page ad on the Washington Post on on Tuesday saying that, you know, America must win the AI war. And so this sort of relative race in AI between the US and China is critical. Today we released humanity's last exam, which is a new evaluation or benchmark of AI models that we produced by getting, you know, math, physics, biology, chemistry professors to provide the hardest questions they could possibly imagine that are relevant to their recent research. To really put the test to the models, to give you a sense, no model is getting above 10% on this test. That being said, you know, what we found is that deep seek, which is the leading Chinese AI lab, their model is actually the top performing or roughly on par with the best American models, which are oh one from. Okay. >> So I think we have been all under the impression that the US was way ahead of China as it relates to AI, in large part because we have access to, you know, Nvidia GPUs and chips and other things that that supposedly the Chinese do not have. I keep hearing from people all week from people, Chinese, Chinese, AI executives that they say, we're so close. And by the way, we're doing it with one hand tied behind our back. Our algos are better. We're actually going to figure out how to do this, do it better than the US, and in even a more energy efficient way, because we don't need these super powerful chips. They happen to be right. >> There's two things happening. First, it is true. It has been true for a long time that the United States has been ahead. And that's been true for, you know, maybe the past decade. That being said, you know, the very recent event on Christmas Day, you know, about a month ago, Deep Seek released a model which, by the way, I think is symbolic that the Chinese lab releases, you know, an earth shattering model on Christmas Day when, you know, the rest of us are sort of celebrating the holiday and they released it to much fanfare. And then they followed up with their reasoning model, Deep Scar one, which is the one that we evaluated as top of the leaderboard. You know, the reality is yes and no. So, you know, the Chinese labs, they have more a100s than than people think, you know, the. >> And these are the highest powered Nvidia chips that they were not supposed to have. >> Yes. My understanding is that is that deep Seac has about 50,000 a100s, which they can't talk about obviously, because it is against the export controls that the United States has put in place. And I think it is true that, you know, I think they have more chips than other people expect, but also going to go forward basis. They are going to be limited by the chip controls and the export controls that we have in place. >> How do you I mean, you work with all you work with everybody. So I don't know if it's fair or unfair, but how do you stack rank these large language models and who ultimately is going to be a winner? Or are they all so close and it gets commoditized? >> The interesting thing that we see right now, so we actually specialize in this. We've produced our seal evaluations, our safety evaluations and alignment labs evaluations, which which measure across many different dimensions. And we measure across math capabilities, coding capabilities, multilingual capabilities and reasoning capabilities, and many different dimensions, including tool use and agent capabilities. And what we see is different models are better at different things, so it's hard to put a clear stack ranking among all the models. You know. For example, the OpenAI models are extremely good at reasoning, but the anthropic models might be really good at code. And sort of there's a there's a diversity of capabilities of the models. That being said, I think what we're seeing in general is the space is becoming more competitive, not less competitive. >> I keep hearing from business leaders here that they're all playing around with, you know, OpenAI or they're playing around with Claude, which is the anthropic model, or they're playing around with Gemini, etc, and then they're going and using llama. They're going to find some open source version to try to get close to what they could approximate these other guys doing because of just the different price points of these things. Do you think that's the future of this? I think in in a Linux world. >> There's definitely a dimension. You know, it comes down to ultimately the level of capabilities and intelligence that are required for your use case. I think ultimately what we're going to see is, you know, what we do with all the leading labs, including OpenAI and Google DeepMind and meta and many others, is continuing to push the frontier and push the boundaries. And so how do we leverage data, given that, you know, as a as an industry, we've sort of run out of publicly available data. How do we generate new data to keep pushing the frontiers? And our belief is that, you know, advanced capabilities are going to enable incredible use cases where where you're going to be willing to pay for those for those increased capabilities. But for the more simplistic use cases, those will probably go more towards open source or more basic models. >> We've been talking all morning about Stargate and the debate happening on Twitter between Sam Altman and Elon Musk, about whether they really have $100 billion or $500 billion. Satya Nadella was sitting in your chair just yesterday saying he's got $80 billion. His money is real. He took to Twitter. What do you make of all of this? You know, all these players. >> You know, so much is on Twitter anyway. So I'm not sure I'm X we should say or yeah X. But I mean I think one thing that is very real, regardless of sort of Stargate specifically as a program, is that the United States is going to need a huge amount of computational capacity and a huge amount of infrastructure. So this was actually in we wrote a letter to the Trump administration to on recommendations on how to ensure that the US stays ahead. And one of them was really around infrastructure. We need to unleash US energy to enable this AI boom. And that's clearly what we're seeing right now, which is, you know, in addition to the Stargate program, many of the major AI companies and major clouds are going to be looking to produce to build giant data centers. >> So the reason I asked about the different companies doing this, do you ultimately think we need five, six, seven companies all trying to build frontier models or. I mean, there's been a talk forever that, you know, in a different if Lina Khan hadn't been running, the FTC would have Amazon wanted to buy anthropic already, for example, or would have Microsoft bought OpenAI or would have some of these folks so there wouldn't be as many everybody competing against each other in the same way? I don't know, maybe you think the competition is great. I just don't know how long, long term, how many models there ultimately will be like that. >> I mean, our view is actually that this is potentially going to be one of the greatest markets or the greatest industries ever. You know, right now, let's say there's between 10 and $20 billion of LM based revenue. And if you believe that we're actually on a track towards superintelligence or AGI, then it stands to reason that that's going to go to $1 trillion or more of revenue. And so if you're looking at a market that's going to go from, let's say, 10 billion to 1 trillion over who knows how many years, I tend to believe a fewer number of years. I think we're sort of in the 2 to 4 range, 2 to 4. >> Two to get to AGI. And what's your version of AGI? >> I think obviously there's many definitions. You know, the definition I believe in is our powerful AI systems that are able to use a computer just like you or I could a",
  "cleaned_transcript": "This time, we're going to be talking about global AI, of course, a topic we've been discussing all week. But for the first time on the show, we have Scale AI founder and CEO Alexander Wang. His company provides accurately labeled data to help companies train their AI tools. Back in 2022, he became the youngest self-made billionaire in the world, which is pretty amazing.  \n\n>> Thanks for having me on.  \n\n>> I want to dive straight into what we were just discussing off-camera: the state of AI in the US versus China. You have some very surprising statistics that I think will, frankly, probably shock some of our viewers.  \n\n>> The AI race and the AI competition between the US and China are among the most critical issues of our time. We took out a full-page ad in *The Washington Post* on Tuesday, emphasizing that America must win the AI race. This relative competition in AI between the US and China is absolutely pivotal. Today, we released humanity's last... exam, which is a new evaluation or benchmark of AI models that we produced by engaging math, physics, biology, and chemistry professors to provide the most challenging questions they could imagine, directly tied to their recent research. This was designed to rigorously test the models. To give you a sense, no model is scoring above 10% on this test. That said, what we found is that DeepSeek, the leading Chinese AI lab, has a model that is either the top performer or roughly on par with the best American models, such as OpenAI's.  \n\n>> So, I think many of us have been under the impression that the US was significantly ahead of China in AI, largely because we have access to Nvidia GPUs and chips, which the Chinese supposedly lack. However, I’ve been hearing all week from Chinese AI executives who say, \"We’re so close. And by the way, we’re doing it with one hand tied behind our back.\" >> Their algorithms are better. They're figuring out how to do this more effectively than the US, and in an even more energy-efficient way, because they don't rely on super powerful chips. And they happen to be right.  \n\n>> There are two things happening here. First, it is true—and has been for a long time—that the United States has been ahead. That's been the case for maybe the past decade. That said, the recent event on Christmas Day, about a month ago, was significant. DeepSeek released a groundbreaking model, which I think is symbolic—a Chinese lab releasing an earth-shattering model on Christmas Day, while the rest of us were celebrating the holiday. They released it with much fanfare, followed by their reasoning model, DeepSeek-1, which we evaluated as the top performer on the leaderboard.  \n\n>> The reality is nuanced. Chinese labs have more A100s than people realize. >> And these are the highest-powered Nvidia chips that they were not supposed to have.  \n>> Yes. My understanding is that DeepSeek has about 50,000 A100s, which they can't openly discuss due to the export controls the United States has implemented. I think it's true that they have more chips than most people expect, but moving forward, they will be limited by these chip and export controls.  \n\n>> How do you—I mean, you work with everyone. So, I don't know if it's fair or unfair, but how do you stack-rank these large language models? Who ultimately is going to be the winner, or are they all so close that it becomes commoditized?  \n\n>> The interesting thing we see right now—and we specialize in this—is that we've produced our SEAL evaluations, safety evaluations, and alignment lab evaluations, which measure performance across many different dimensions. And we measure across math capabilities, coding capabilities, multilingual capabilities, reasoning capabilities, and many other dimensions, including tool use and agent capabilities. What we see is that different models excel in different areas, making it difficult to establish a clear stack ranking among them. For example, OpenAI models are extremely strong in reasoning, while Anthropic models might excel in coding. There’s a diversity of capabilities across the models. That said, I think what we’re seeing overall is that the space is becoming more competitive, not less. I keep hearing from business leaders that they’re experimenting with OpenAI, Claude—Anthropic’s model—or Gemini, and then they’re exploring open-source alternatives like LLaMA to approximate what these models can do. >> There’s definitely a dimension to this, and it ultimately comes down to the level of capabilities and intelligence required for your specific use case. I think what we’re going to see is a continuation of what we’re already doing with leading labs like OpenAI, Google DeepMind, Meta, and many others—pushing the frontier and expanding the boundaries of what’s possible. A key challenge is leveraging data, especially since, as an industry, we’ve largely exhausted publicly available data. The question becomes: how do we generate new data to keep advancing? Our belief is that advanced capabilities will unlock incredible use cases, and for those, people will be willing to pay a premium. However, for simpler use cases, open-source or more basic models will likely suffice. >> We’ve been discussing Stargate and the ongoing debate on Twitter—or X, as it’s now called—between Sam Altman and Elon Musk about whether they have $100 billion or $500 billion. Satya Nadella was here just yesterday, stating he has $80 billion, and his funding is real. He even took to Twitter to emphasize this. What do you make of all these developments and the players involved? >> Well, so much of this conversation is happening on Twitter—or X, as we should say now. But regardless of Stargate specifically, one thing is very clear: the United States will need an enormous amount of computational capacity and infrastructure to support this AI boom. In fact, we wrote a letter to the Trump administration with recommendations on how to ensure the US maintains its lead. One key recommendation was focused on infrastructure—specifically, the need to unleash US energy capabilities to enable this AI expansion. That’s exactly what we’re seeing unfold right now. The Stargate program highlights how many major AI companies and cloud providers are aiming to build massive data centers. The question is: do we ultimately need five, six, or seven companies all trying to develop frontier models? There’s been ongoing speculation—for instance, if Lina Khan hadn’t been leading the FTC, Amazon might have already acquired Anthropic, or Microsoft might have bought OpenAI, potentially reducing the number of competitors. Do you think this level of competition is beneficial? I’m just not sure how many of these models will persist in the long term.  \n\nOur perspective is that this could become one of the greatest markets or industries ever. Currently, let’s estimate there’s between $10 and $20 billion in revenue from language models. If you believe we're on a trajectory toward superintelligence or AGI, then it stands to reason that the market could grow to $1 trillion or more in revenue. So, if you're looking at a market poised to expand from, say, $10 billion to $1 trillion over an uncertain number of years—though I tend to believe it will happen in fewer years, perhaps in the 2 to 4 range—that's a monumental shift. >> Two to four years to reach AGI? And what's your definition of AGI? >> There are many definitions, of course. The one I subscribe to is AI systems powerful enough to use a computer just as you or I would.",
  "success": true,
  "total_tokens": 14912
}